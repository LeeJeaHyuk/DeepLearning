{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac511807",
   "metadata": {},
   "source": [
    "####\n",
    "다중 분류라 타겟값 원핫 해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe41c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38212293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, InputLayer, Add, BatchNormalization, Dropout\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29a199c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 파일 생성 및 경로\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def file_make(filename):\n",
    "    now = datetime.datetime.now()\n",
    "    date =  now.strftime('%Y-%m-%d')\n",
    "\n",
    "    file_path = './'+ filename +'/' + date\n",
    "    os.makedirs(file_path,exist_ok=True)\n",
    "    print(file_path)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6685a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trn_data = pd.read_csv('./data/2022-12-14/trn_data.csv')\n",
    "tst_data = pd.read_csv('./data/2022-12-14/tst_data.csv')\n",
    "sub = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4bd9d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_num(df):\n",
    "    df['class'] = df['class'].replace({'A':0,'B':1,'C':2})\n",
    "    return df\n",
    "\n",
    "def num_to_cat(df):\n",
    "    df['class'] = df['class'].replace({0:'A',1:'B',2:'C'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c996b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = cat_to_num(trn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f875e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = ['id', \n",
    "          'class', \n",
    "         ]\n",
    "features = [feat for feat in trn_data.columns if feat not in remove]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fa13eef",
   "metadata": {},
   "source": [
    "### 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a187d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "drop_out_pct = 0.45\n",
    "l2 = 80e-6\n",
    "\n",
    "def nn_model():\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    activation_func = 'swish'\n",
    "    inputs = Input(shape = (len(features)))\n",
    "    \n",
    "    x = Dense(1024, \n",
    "              #use_bias  = True, \n",
    "              kernel_regularizer = tf.keras.regularizers.l2(l2), \n",
    "              activation = activation_func)(inputs)\n",
    "    \n",
    "    x = Dropout(drop_out_pct)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    \n",
    "    x = Dense(512, \n",
    "              #use_bias  = True, \n",
    "              kernel_regularizer = tf.keras.regularizers.l2(l2), \n",
    "              activation = activation_func)(x)\n",
    "    \n",
    "    x = Dropout(drop_out_pct)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(128, \n",
    "              #use_bias  = True, \n",
    "              kernel_regularizer = tf.keras.regularizers.l2(l2), \n",
    "              activation = activation_func)(x)\n",
    "\n",
    "    x = Dropout(drop_out_pct)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "\n",
    "    x = Dense(1 , \n",
    "              #use_bias  = True, \n",
    "              #kernel_regularizer = tf.keras.regularizers.l2(30e-6),\n",
    "              activation = 'sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b40b5bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 19)]              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1024)              20480     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 617,729\n",
      "Trainable params: 614,401\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 87.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "architecture = nn_model()\n",
    "architecture.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4719a4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Defining model parameters...\n",
    "BATCH_SIZE         = 128\n",
    "EPOCHS             = 512 \n",
    "EPOCHS_COSINEDECAY = 512 \n",
    "DIAGRAMS           = True\n",
    "USE_PLATEAU        = True\n",
    "INFERENCE          = False\n",
    "VERBOSE            = 0 \n",
    "TARGET             = 'class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6be75d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Defining model training function...\n",
    "def fit_model(X_train, y_train, X_val, y_val, run = 0):\n",
    "    '''\n",
    "    '''\n",
    "    lr_start = 0.1\n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    epochs = EPOCHS    \n",
    "    lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.7, patience = 4, verbose = VERBOSE)\n",
    "    es = EarlyStopping(monitor = 'val_loss',patience = 48, verbose = 1, mode = 'min', restore_best_weights = True)\n",
    "    tm = tf.keras.callbacks.TerminateOnNaN()\n",
    "    callbacks = [lr, es, tm]\n",
    "    \n",
    "    # Cosine Learning Rate Decay\n",
    "    if USE_PLATEAU == False:\n",
    "        epochs = EPOCHS_COSINEDECAY\n",
    "        lr_end = 0.0002\n",
    "\n",
    "        def cosine_decay(epoch):\n",
    "            if epochs > 1:\n",
    "                w = (1 + math.cos(epoch / (epochs - 1) * math.pi)) / 2\n",
    "            else:\n",
    "                w = 1\n",
    "            return w * lr_start + (1 - w) * lr_end\n",
    "        \n",
    "        lr = LearningRateScheduler(cosine_decay, verbose = 0)\n",
    "        callbacks = [lr, tm]\n",
    "        \n",
    "    model = nn_model()\n",
    "    \n",
    "    optimizer_func = tf.keras.optimizers.Adam(learning_rate = lr_start)\n",
    "    loss_func = tf.keras.losses.CategoricalCrossentropy()\n",
    "    model.compile(optimizer = optimizer_func, loss = loss_func)\n",
    "    \n",
    "    X_val = scaler.transform(X_val)\n",
    "    validation_data = (X_val, y_val)\n",
    "    \n",
    "    history = model.fit(X_train, \n",
    "                        y_train, \n",
    "                        validation_data = validation_data, \n",
    "                        epochs          = epochs,\n",
    "                        verbose         = VERBOSE,\n",
    "                        batch_size      = BATCH_SIZE,\n",
    "                        shuffle         = True,\n",
    "                        callbacks       = callbacks\n",
    "                       )\n",
    "    \n",
    "    history_list.append(history.history)\n",
    "    print(f'Training loss:{history_list[-1][\"loss\"][-1]:.3f}')\n",
    "    callbacks, es, lr, tm, history = None, None, None, None, None\n",
    "    \n",
    "    \n",
    "    y_val_pred = model.predict(X_val, batch_size = BATCH_SIZE, verbose = VERBOSE)\n",
    "    y_val_pred = [1 if x > 0.5 else 0 for x in y_val_pred]\n",
    "    \n",
    "    score = accuracy_score(y_val, y_val_pred)\n",
    "    print(f'Fold {run}.{fold} | {str(datetime.datetime.now() - start_time)[-12:-7]}'\n",
    "          f'| ACC: {score:.5f}')\n",
    "    \n",
    "    score_list.append(score)\n",
    "    \n",
    "    tst_data_scaled = scaler.transform(tst_data[features])\n",
    "    tst_pred = model.predict(tst_data_scaled)\n",
    "    predictions.append(tst_pred)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "88848b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 49: early stopping\n",
      "Training loss:7.213\n",
      "Fold 0.0 | 00:03| ACC: 0.77358\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 49: early stopping\n",
      "Training loss:7.143\n",
      "Fold 0.1 | 00:03| ACC: 0.62264\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 49: early stopping\n",
      "Training loss:7.373\n",
      "Fold 0.2 | 00:03| ACC: 0.67308\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 49: early stopping\n",
      "Training loss:6.716\n",
      "Fold 0.3 | 00:03| ACC: 0.61538\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 49: early stopping\n",
      "Training loss:7.306\n",
      "Fold 0.4 | 00:03| ACC: 0.75000\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "OOF AUC: 0.68694\n",
      "CPU times: total: 12.6 s\n",
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create empty lists to store NN information...\n",
    "history_list = []\n",
    "score_list   = []\n",
    "predictions  = []\n",
    "\n",
    "# Define kfolds for training purposes...\n",
    "kf = KFold(n_splits = 5)\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(kf.split(trn_data)):\n",
    "    X_train, X_val = trn_data.iloc[trn_idx][features], trn_data.iloc[val_idx][features]\n",
    "    y_train, y_val = trn_data.iloc[trn_idx][TARGET], trn_data.iloc[val_idx][TARGET]\n",
    "    \n",
    "    fit_model(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "print(f'OOF AUC: {np.mean(score_list):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a30541e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Populated the prediction on the submission dataset and creates an output file\n",
    "# sub['Transported'] = np.array(predictions).mean(axis = 0)\n",
    "# sub['Transported'] = np.where(sub['Transported'] > 0.5, True, False)\n",
    "# sub.to_csv('submission_nn01.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fbe3f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./data/sample_submission.csv')\n",
    "sub = sub.drop(['class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3333a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_data['class'] = np.array(predictions).mean(axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d0525e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.merge(sub, tst_data[['id','class']], how='outer', on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1b898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['class'] = np.where(submit['class'] > 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab7456",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = num_to_cat(submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "857a2610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./submit_file/2022-12-14\n"
     ]
    }
   ],
   "source": [
    "number = '01'\n",
    "submit_path = file_make('submit_file') +'/submitionDNN' + number +'.csv'\n",
    "submit.to_csv(submit_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9298fecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>TEST_170</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>TEST_171</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>TEST_172</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>TEST_173</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>TEST_174</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  class\n",
       "0    TEST_000  False\n",
       "1    TEST_001   True\n",
       "2    TEST_002   True\n",
       "3    TEST_003   True\n",
       "4    TEST_004  False\n",
       "..        ...    ...\n",
       "170  TEST_170   True\n",
       "171  TEST_171   True\n",
       "172  TEST_172   True\n",
       "173  TEST_173   True\n",
       "174  TEST_174   True\n",
       "\n",
       "[175 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_check = pd.read_csv(submit_path)\n",
    "submit_check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac511807",
   "metadata": {},
   "source": [
    "####\n",
    "다중 분류라 타겟값 원핫 해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3b467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d86e5f3e65a370f4f0c7c6c157476db0f2576129ce19971a1015c727da11cca3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
